<html>
<title>Workshop on New Forms of Generalization in Deep Learning and Natural Language Processing</title>
<body bgcolor=grey style="font-family: Algerian;">

<center>
<br>
<table bgcolor=white>
<tr>
<td width=50> </td>
<td width=600>
<br>
<center><h2>Workshop on New Forms of Generalization in Deep Learning and Natural Language Processing</h2></center>
</td>
<td width=50> </td>
</tr>
<tr><td colspan=3><br></td></tr>

<tr><td></td>
<td>
<h3>Overview</h3>
<p>Deep learning has brought a wealth of state-of-the-art results and new capabilities. Although methods have achieved near human-level performance on many benchmarks, numerous recent studies imply that these benchmarks only weakly test their intended purpose, and that simple examples produced either by human or machine, cause systems to fail spectacularly. For example, a recently released textual entailment demo was criticized on social media for predicting that “John killed Mary” entails “Mary killed John” with 92% confidence.1 Such surprising failures combined with the inability to interpret state-of-the-art models have eroded confidence in our systems, and while these systems are not perfect, the real flaw lies with our benchmarks that do not adequately measure a model’s ability to generalize, and are thus easily gameable.</p>

<p>This workshop provides a venue for exploring new approaches for measuring and enforcing generalization in models. We will solicit work in the following areas:</p>

<ol>
<li><b>Analysis of existing models and their failings</b></li>
<li><b>Creation of new evaluation paradigms</b>, e.g. zero-shot learning, Winnograd schema, and datasets that avoid explicit types of gamification.</li>
<li><b>Modeling advances</b> such as regularization, compositionality, interpretability, inductive bias, multi-task learning, and other methods that promote generalization.</li>
</ol>
<p>Some of our goals are similar in spirit to those of the recent “Build it Break it” workshop (Ettinger et al., 2017). However, we propose going beyond identifying areas of weakness (i.e. “breaking” existing systems), and discussing scalable evaluations that more rigorously test generalization as well as modeling techniques for enforcing it.</p>

<h3>Submission Formats</h3>
Submissions fall into one of three categories:
<ol>
<li>Adversarial examples / Breaking an existing system<div style="float: right; clear: right;">– 2 pages</div></li>
<li>Archival dataset, benchmark, or modeling papers<div style="float: right; clear: right;">– 4 pages</div></li>
<li>Non-archival cross submissions<div style="float: right; clear: right;">– 8 pages</div></li>
</ol>
Categories (1) and (2) are expected to use the NAACL-HLT 2018 style guides: <a href="http://naacl2018.org/downloads/naaclhlt2018-latex.zip">LaTex</a>, <a href="http://naacl2018.org/downloads/naaclhlt2018-word.zip">Word</a>, or <a href="https://www.overleaf.com/11236538xkqdqtnqjgty">Overleaf</a>.
</td>
<td></td></tr>

<tr><td colspan=3><br></td></tr>
<tr><td></td><td>
<h3>Invited Speakers and Panelists:</h3>
<br>
</td><td></td></tr>


<tr><td colspan=3><br></td></tr>
<tr><td></td><td>
<h3>Organizers:</h3>
<a href="https://homes.cs.washington.edu/~my89/">Mark Yatskar</a>, Univ Washington<br>
<a href="http://www.YonatanBisk.com">Yonatan Bisk</a>, Univ Washington<br>
<a href="https://levyomer.wordpress.com">Omer Levy</a>, Univ Washington<br>
<br>
</td><td></td></tr>

<tr><td colspan=3><br></td></tr>
<tr><td></td><td>
<h3>Steering committee:</h3>
<br>
</td><td></td></tr>

<tr><td colspan=3><br></td></tr>
<tr><td></td><td>
<h3>Program committee:</h3>
<br>
</td><td></td></tr>




</table>
</body>
</html>
