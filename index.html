<html>
<head>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
<title>Workshop on New Forms of Generalization in Deep Learning and Natural Language Processing</title>
<style type="text/css"> a {text-decoration:none;} </style>
<style type="text/css"> a:visited {color: DodgerBlue  }</style>
<style type="text/css"> a {color: DodgerBlue  }</style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-8024377-9"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-8024377-9');
</script>



</head>
<body bgcolor=white style="font-family: 'Helvetica Light';">

<center>
<br>
<table bgcolor=F8F8F8 width=1000>
<tr>
<td width=50> </td>
<td width=800>
<br>
<center><font size=6>Workshop on New Forms of Generalization<br> in Deep Learning and Natural Language Processing</font></center>
</td>
</tr>
<tr><td colspan=3><br></td></tr>



<tr><td></td>
<td>

<div style="float: right; clear:right;display: inline"><font color="red"><b>June 5th at NAACL 2018!</b></font></div>
<br>
<center><p style="background:lightyellow;"><b>TL;DR:</b> We build models that work well on our datasets but when we play with them we are surprised that they are brittle and break.<br/>Let’s analyze their failings propose new evaluations &amp; models.</p></center>
<br>
<center><table bgcolor=e6e6ff style="text-align:center" width="50%">
<tr><td colspan=3><font size=5><u>Expected Schedule</u></font></td>
<tr><td colspan=3 style="text-align:center"><a href="https://naacl2018.wordpress.com/2018/01/19/onsite-childcare/"><font color=red>Onsite Childcare Available</font></a></td></tr>
<tr><td><u>Time</u></td><td><u>Speaker</u></td><td><u>Topic</u></td></tr>
<tr><td>9:00 - 9:15</td><td>Organizers</td><td>Welcome and Introduction</td></tr>
<tr><td>9:15 - 9:50</td><td>Yejin Choi</td></tr>
<tr><td>9:50 - 10:25</td><td>Dan Roth</td></tr>
<tr><td>10:25 - 10:35</td><td>Break</td></tr>
<tr><td>10:35 - 11:10</td><td>Percy Liang</td></tr>
<tr><td>11:10 - 11:45</td><td>Ndapa Nakashole</td></tr>
<tr><td>11:45 - 12:20</td><td>Hal Daumé III</td></tr>
<tr><td>12:20 - 1:30</td><td>Lunch</td><td>Eating Food</td></tr>
<tr><td>1:30 - 2:30</td><td>Poster Session</td><td></td></tr>
<tr><td>2:45 - 3:20</td><td>Sam Bowman</td><td></td></tr>
<tr><td>3:20 - 3:55</td><td>Devi Parikh</td><td></td></tr>
<tr><td>4:10 - 5:10</td><td>Panel</td><td>Discussion questions from audience</td></tr>
<tr><td>5:10 - 5:15</td><td>Organizers</td><td>Closing Remarks</td></tr>
</table>
</center>
<b style="color:red;"><p id="demo"></p></b>
<font size=5>Overview</font>
<p style="text-align: justify;">Deep learning has brought a wealth of state-of-the-art results and new capabilities. Although methods have achieved near human-level performance on many benchmarks, numerous recent studies imply that these benchmarks only weakly test their intended purpose, and that simple examples produced either by human or machine, cause systems to fail spectacularly<sup><a href="#one">[1]</a><a href="#two">[2]</a><a href="#three">[3]</a><a href="#four">[4]</a><a href="#five">[5]</a><a href="#six">[6]</a><a href="#seven">[7]</a></sup>. For example, a recently released textual entailment demo was criticized on social media for predicting:

  <center><table><tr><td width="30%">“John killed Mary”</td><td width="30%"><center>&#8594;</center></td><td width="30%">“Mary killed John”</td></tr>
          <tr><td colspan=3><center><font color=red>Entailing</font> with 92% confidence</center></td></tr></table></center>
<br>
Such surprising failures combined with the inability to interpret state-of-the-art models have eroded confidence in our systems, and while these systems are not perfect, the real flaw lies with our benchmarks that do not adequately measure a model’s ability to generalize, and are thus easily gameable.</p>
<p>This workshop provides a venue for exploring new approaches for measuring and enforcing generalization in models. We are soliciting work in the following areas:</p>

<ul>
<li><strong>Analysis of existing models and their failings</strong></li>
<li><strong>Creation of new evaluation paradigms</strong>, <br>e.g. zero-shot learning, Winnograd schema, and datasets that avoid explicit types of gamification.</li>
<li><strong>Modeling advances</strong> <br>regularization, compositionality, interpretability, inductive bias, multi-task learning, and other methods that promote generalization.</li>
</ul>
<p text-align: justify;>Some of our goals are similar in spirit to those of the recent “Build it Break it” shared task.<sup><a href="#eight">[8]</a></sup> However, we propose going beyond identifying areas of weakness (i.e. “breaking” existing systems), and discussing scalable evaluations that more rigorously test generalization as well as modeling techniques for enforcing it.</p>
</td><td></td></tr>
<tr><td></td></tr>
<tr ><td></td><td>

</td>
<td></td>
</tr>

<tr><td></td><td>

<br>
<font size=5>Accepted Posters</font>
<br>
<br>
<table style="text-align:center" border=1>
<tr><td width="50%">Commonsense mining as knowledge base completion?<br>A study on the impact of novelty</td><td width="50%">Stanislaw Jastrzebski, Dzmitry Bahdanau, Seyedarian Hosseini, Michael Noukhovitch, Yoshua Bengio and Jackie Cheung</td></tr>
<tr><td width="50%">Deep learning evaluation using deep linguistic processing</td><td width="50%">Alexander Kuhnle and Ann Copestake</td></tr>
<tr><td width="50%">The Fine Line between Linguistic Generalization and<br>Failure in Seq2Seq-Attention Models </td><td width="50%">Noah Weber, Leena Shekhar and Niranjan Balasubramanian</td></tr>
<tr><td width="50%">Extrapolation in NLP</td><td width="50%">Jeff Mitchell, Pontus Stenetorp, Pasquale Minervini and Sebastian Riedel</td></tr>
<tr><td width="50%">Towards Inference-Oriented Reading Comprehension: ParallelQA</td><td width="50%">Soumya Wadhwa, Varsha Embar, Matthias Grabmair and Eric Nyberg</td></tr>
</table>
<br>
<br>
<font size=5>Accepted Cross / Non Archival Submissions (to be presented as posters)</font>
<br>
<br>
<table style="text-align:center" border=1>
<tr><td width="50%">Annotation Artifacts in Natural Language Inference Data</td><td width="50%">Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel Bowman and Noah A. Smith</td></tr>
<tr><td width="50%">Stress Test Evaluation for Natural Language Inference</td><td width="50%">Abhilasha Ravichander, Aakanksha Naik, Norman Sadeh, Carolyn Rose and Graham Neubig</td></tr>
<tr><td width="50%">Deep RNNs Learn Hierarchical Syntax</td><td width="50%">Terra Blevins, Omer Levy and Luke Zettlemoyer</td></tr>
<tr><td width="50%">Adversarial Example Generation with Syntactically Controlled Paraphrase Networks</td><td width="50%">Mohit Iyyer, John Wieting, Kevin Gimpel and Luke Zettlemoye</td></tr>
<tr><td width="50%">Evaluating Compositionality in Sentence Embeddings</td><td width="50%">Ishita Dasgupta, Demi Guo, Andreas Stuhlmüller, Samuel Gershman and Noah Goodman</td></tr>
</table>
<br>
<br>
<font size=5 color=cc3399>Organizers:</font><br>
<ul style="list-style: none;">
<li><a href="https://homes.cs.washington.edu/~my89/">Mark Yatskar</a><div style="float: right; clear: right;">Univ Washington</div></li>
<li><a href="http://www.YonatanBisk.com">Yonatan Bisk</a><div style="float: right; clear: right;">Univ Washington</div></li>
<li><a href="https://levyomer.wordpress.com">Omer Levy</a><div style="float: right; clear: right;">Univ Washington</div></li>
</ul>
</td><td></td></tr>

<tr><td></td><td>
<font size=5 color=6600cc>Steering committee:</font><br>
<ul  style="list-style: none;">
<li>Yejin Choi      <div style="float: right; clear: right;">University of Washington</div></li>
<li>Devi Parikh     <div style="float: right; clear: right;">Georgia Tech / Facebook AI Research</div></li>
<li>Dan Roth        <div style="float: right; clear: right;">University of Pennsylvania</div></li>
</ul>
</td><td></td></tr>

<tr><td></td><td>
<font size=5>Program committee:</font>
<ul  style="list-style: none;">
<li>Jacob Andreas      <div style="float: right; clear: right;"> UC Berkeley</div></li>
<li>Antoine Bosselut   <div style="float: right; clear: right;"> U Washington</div></li>
<li>Kai-Wei Chang      <div style="float: right; clear: right;"> UC Los Angeles</div></li>
<li>Eunsol Choi        <div style="float: right; clear: right;"> U Washington</div></li>
<li>Christos Christodoulopoulos  <div style="float: right; clear: right;"> Amazon, Inc</div></li>
<li>Ryan Cotterell     <div style="float: right; clear: right;"> Johns Hopkins U</div></li>
<li>Greg Durrett       <div style="float: right; clear: right;"> UT Austin</div></li>
<li>Nicholas FitzGerald <div style="float: right; clear: right;"> U Washington</div></li>
<li>Maxwell Forbes      <div style="float: right; clear: right;"> U Washington</div></li>
<li>Spandana Gella      <div style="float: right; clear: right;"> Edinburgh U</div></li>
<li>Luheng He           <div style="float: right; clear: right;"> U Washington</div></li>
<li>Srinivasan Iyer     <div style="float: right; clear: right;"> U Washington</div></li>
<li>Mohit Iyyer         <div style="float: right; clear: right;"> UMass Amherst</div></li>
<li>Robin Jia           <div style="float: right; clear: right;"> Stanford U</div></li>
<li>Ioannis Konstas     <div style="float: right; clear: right;"> Heriot-Watt U</div></li>
<li>Jonathan Kummerfeld <div style="float: right; clear: right;"> U Michigan</div></li>
<li>Alice Lai           <div style="float: right; clear: right;"> UI Urbana-Champaign</div></li>
<li>Mike Lewis          <div style="float: right; clear: right;"> Facebook AI Research</div></li>
<li>Tal Linzen          <div style="float: right; clear: right;"> Johns Hopkins U</div></li>
<li>Ishan Misra         <div style="float: right; clear: right;"> Carnegie Mellon U</div></li>
<li>Vicente Ordonez     <div style="float: right; clear: right;"> U Virginia</div></li>
<li>Siva Reddy          <div style="float: right; clear: right;"> Stanford U</div></li>
<li>Alan Ritter         <div style="float: right; clear: right;"> Ohio State U</div></li>
<li>Rajhans Samdani     <div style="float: right; clear: right;"> Spoke</div></li>
<li>Sameer Singh        <div style="float: right; clear: right;"> UC Irvine</div></li>
<li>Alane Suhr          <div style="float: right; clear: right;"> Cornell U</div></li>
<li>Chen-Tse Tsai       <div style="float: right; clear: right;"> Bloomberg LP</div></li>
<li>Shyam Upadhyay      <div style="float: right; clear: right;"> U Pennsylvania</div></li>
<li>Andreas Vlachos     <div style="float: right; clear: right;"> U Sheffield</div></li>
</ul>
</td><td></td></tr>

<tr><td></td><td>
<font size=5>Citations:</font>
<ol>
<li>Levy et al. <i>Do Supervised Distributional Methods Really Learn Lexical Inference Relations?</i> NAACL 2015 <div style="float: right; clear: right;"><a id="one" href="http://www.aclweb.org/anthology/N15-1098">[link]</a></div></li> 
<li>Moosavi &amp; Strube <i> Lexical Features in Coreference Resolution: To be Used With Caution</i> ACL 2017 <div style="float: right; clear: right;"><a id="#two" href="http://aclweb.org/anthology/P17-2003">[link]</a></div></li>
<li>Agrawal et al. <i>C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0 Dataset</i> 2017 <div style="float: right; clear: right;"><a id="#three" href="https://arxiv.org/abs/1704.08243">[link]</a></div></li>
<li>Yatskar et al. <i>Commonly Uncommon: Semantic Sparsity in Situation Recognition</i> CVPR 2016 <div style="float: right; clear: right;"><a id="#four" href="https://arxiv.org/abs/1612.00901">[link]</a></div></li>
<li>Jia &amp; Liang <i>Adversarial Examples for Evaluating Reading Comprehension Systems</i> EMNLP 2017 <div style="float: right; clear: right;"><a id="#five" href="https://arxiv.org/abs/1707.07328">[link]</a></div></li>
<li>Levy et al. <i>Zero-Shot Relation Extraction via Reading Comprehension</i> CoNLL 2017 <div style="float: right; clear: right;"><a id="#six" href="https://arxiv.org/abs/1706.04115">[link]</a></div></li>
<li>Belinkov &amp; Bisk <i>Synthetic and Natural Noise Both Break Neural Machine Translation</i> ICLR 2018<div style="float: right; clear: right;"><a id="#seven" href="https://arxiv.org/abs/1711.02173">[link]</a></div></li>
<li>Ettinger et al. <i>Towards Linguistically Generalizable NLP Systems: A Workshop and Shared Task</i> EMNLP Wksp 2017 <div style="float: right; clear: right;"><a id="#eight" href="https://arxiv.org/abs/1711.01505">[link]</a></div></li>
</ol>
</td><td></td></tr>





</table>

<script>
// Set the date we're counting down to
var countDownDate = new Date("March 16, 2018 23:59:59 GMT-1200")

// Update the count down every 1 second
var x = setInterval(function() {
	

// Get todays date and time
  var d = new Date()
  
  var now = d.getTime();

  now = now - (d.getTimezoneOffset() * 60000);
  var then = countDownDate.getTime() - (countDownDate.getTimezoneOffset() * 60000)

  // Find the distance between now an the count down date
  var distance = then - now;

  // Time calculations for days, hours, minutes and seconds
  var days = Math.floor(distance / (1000 * 60 * 60 * 24));
  var hours = Math.floor((distance % (1000 * 60 * 60 * 24)) / (1000 * 60 * 60));
  var minutes = Math.floor((distance % (1000 * 60 * 60)) / (1000 * 60));
  var seconds = Math.floor((distance % (1000 * 60)) / 1000);

  // Display the result in the element with id="demo"
  document.getElementById("demo").innerHTML = "Submission deadline in " + days + "d " + hours + "h "
  + minutes + "m " + seconds + "s ";

  // If the count down is finished, write some text 
  if (distance < 0) {
    clearInterval(x);
    document.getElementById("demo").innerHTML = "";
  }
}, 1000);
</script>


</body>
</html>
